# -*- coding: utf-8 -*-
"""Diabetes_Prediction&_Analysis.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1nWB1IbH8vCv6WDlN0QsXKlzqfbjujnvz
"""



import pandas as pd
import numpy
import os
import seaborn as sns
import plotly.express as px
file_path = '/content/diabetes_binary_5050split_health_indicators_BRFSS2015.csv'
data = pd.read_csv(file_path)
data.info()









data.describe()

import matplotlib.pyplot as plt

columns1 = ['BMI', 'PhysHlth']

plt.figure(figsize=(10, 5))
for i, column in enumerate(columns1):
    plt.subplot(2, 2, i+1)
    plt.hist(data[column], bins=20)
    plt.title(f"{column} - Before Normalization")



from sklearn.preprocessing import StandardScaler

columns1 = ['BMI', 'PhysHlth']

scaler = StandardScaler()


data[columns1] = scaler.fit_transform(data[columns1])



correlation_coefficient = data['BMI'].corr(data['PhysHlth'])
covariance = data['BMI'].cov(data['PhysHlth'])

print(f"Correlation Coefficient (after normalization): {correlation_coefficient}")
print(f"Covariance (after normalization): {covariance}")

plt.hist(data['Age'], bins=10,  rwidth=0.8)
plt.xlabel('Age')
plt.ylabel('Frequency')
plt.title('Equal-Width Histogram of Age (Width = 10)')
plt.show()



data.describe()

file_path = '/content/diabetes_012_health_indicators_BRFSS2015.csv'
data = pd.read_csv(file_path)
missing_values = data.isnull().sum()
print(missing_values)

data.head()

plt.figure(figsize=(10, 5))
for i, column in enumerate(columns1):
    plt.subplot(2, 2, i+1)
    plt.hist(data[column], bins=20)
    plt.title(f"{column} - After Normalization")

correlation_coefficient = data['BMI'].corr(data['PhysHlth'])
covariance = data['BMI'].cov(data['PhysHlth'])

print(f"Correlation Coefficient (after normalization): {correlation_coefficient}")
print(f"Covariance (after normalization): {covariance}")

bin_depth = 10

data['Age'] = data['Age'].groupby(data['Age'] // bin_depth * bin_depth).transform('mean')

plt.hist(data['Age'], bins=10)
plt.xlabel('Age')
plt.ylabel('Frequency')
plt.title('Equal-Width Histogram of Age (Width = 10)')
plt.show()

target = data['Diabetes_binary'].value_counts()
print(target)

from sklearn.model_selection import train_test_split
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import accuracy_score, f1_score

X = data.drop('Diabetes_binary', axis=1)
y = data['Diabetes_binary']
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

model = LogisticRegression()
model.fit(X_train, y_train)

predictions = model.predict(X_test)
predictions

accuracy = accuracy_score(y_test, predictions)
f1 = f1_score(y_test, predictions)

print(f"Accuracy: {accuracy}")
print(f"F1 Score: {f1}")

from sklearn.metrics import classification_report
report = classification_report(y_test, predictions)
print(report)

from sklearn.metrics import roc_curve, roc_auc_score

fpr, tpr, thresholds = roc_curve(y_test, predictions)
plt.figure(figsize=(8, 6))
plt.plot(fpr, tpr, label='ROC curve (area = %0.2f)' % roc_auc_score(y_test, predictions))
plt.plot([0, 1], [0, 1], 'r--')  # Random classifier
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.title('Receiver Operating Characteristic (ROC) Curve')
plt.legend()
plt.show()

ax = data['Age'].value_counts().plot(kind='bar', title='The Age Distribution')
ax.set_xlabel('Age')
ax.set_ylabel('Count')
plt.show()

ax = data['Sex'].value_counts().plot(kind='bar', title='Sex Distribution')
ax.set_xlabel('Sex (0=men, 1=women)')
ax.set_ylabel('Count')
plt.show()

ax= data['BMI'].value_counts().plot(kind='kde', title='BMI Distribution')
ax.set_xlabel('BMI')
ax.set_ylabel('Count')
plt.show()

data['Education'].value_counts().plot(kind='bar', title='Education level of Patients')
ax.set_xlabel('Education')
ax.set_ylabel('Count')
plt.show()

#bivariate analysis
temp_feat = data.drop(['Diabetes_binary'], axis=1).copy()
temp_feat.head()

temp_y = data['Diabetes_binary'].copy()
temp_y.head()

import seaborn as sns
sns.pairplot(temp_feat, vars=['HighBP', 'HighChol', 'BMI',
              'Fruits','PhysHlth',  'Sex', 'Age', 'Income'])
plt.show()

temp_feat.corr()

sns.set(rc = {'figure.figsize':(25
                                , 20)})
sns.heatmap(temp_feat.corr(), annot=True, vmin = -1, vmax = 1)

ax = data.groupby('Diabetes_binary').mean()
ax

ax = data.groupby('Diabetes_binary')['PhysHlth'].mean() \
    .plot(kind='bar', figsize=(5,5), title='Physical Health and Diabetes',
          ylabel='Average Fruits Consumption', xlabel='Diabetes')
plt.show()

from sklearn.tree import DecisionTreeRegressor
from sklearn.model_selection import train_test_split
from sklearn.metrics import mean_squared_error

import pandas as pd
from sklearn.preprocessing import StandardScaler

df = pd.read_csv('/content/diabetes_binary_5050split_health_indicators_BRFSS2015.csv')

print("Original DataFrame:")
print(df.head())

columns_to_normalize = ['BMI', 'PhysHlth']

scaler = StandardScaler()

df[columns_to_normalize] = scaler.fit_transform(df[columns_to_normalize])

print("\nNormalized DataFrame:")
print(df.head())

import matplotlib.pyplot as plt

data = pd.read_csv('/content/diabetes_binary_5050split_health_indicators_BRFSS2015.csv')

data['Age'] = data['Age'].astype(int)

plt.hist(data['Age'], bins=range(min(data['Age']), max(data['Age']) + 10, 10), edgecolor='black')
plt.title('Equal-Width Histogram of Age')
plt.xlabel('Age')
plt.ylabel('Frequency')
plt.show()



g=data.groupby(['Diabetes_binary','HighChol']).agg({'BMI':'count'})
chol = 100 * g['BMI'] / g.groupby(['Diabetes_binary'])['BMI'].transform('sum')
chol
sns.countplot(x='Diabetes_012', hue='HighChol',data  = data)

import numpy as np
import tensorflow.compat.v1 as tf
tf.disable_v2_behavior()
import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split
import pandas as pd
from sklearn.metrics import accuracy_score,f1_score,recall_score,precision_score
from sklearn.metrics import confusion_matrix
from sklearn.metrics import ConfusionMatrixDisplay


import time,os
dir_ = str(time.time())
os.mkdir(dir_)
print("\n\n\n\n["+dir_+"] >>>>>>>>>>>>>")


df = pd.read_csv("/content/diabetes_binary_5050split_health_indicators_BRFSS2015.csv")

y = df["Diabetes_binary"].to_numpy()

X = df.drop(["Diabetes_binary"], axis = 1).drop(["Smoker"], axis = 1).to_numpy()
X_train, X_test, y_train, y_test = train_test_split(X,y, test_size=0.16, random_state = 2021, stratify=y)



unique, counts = np.unique(y_train, return_counts=True)
print("Train:  ",dict(zip(unique, counts)))

unique, counts = np.unique(y_test, return_counts=True)
print("Test:  ",dict(zip(unique, counts)))


n = X_train.shape[1]
m = 2*n

learning_rate = 0.01
epochs = 1000



X_train_t = tf.placeholder(tf.float32, shape=[None, n])
y_train_t = tf.placeholder(tf.float32, shape=None)

mu = tf.get_variable(name="mu", shape=[m * n], initializer=tf.random_normal_initializer(0, 1))
sigma = tf.get_variable(name="sigma", shape = [m * n], initializer=tf.random_normal_initializer(0, 1))
w = tf.get_variable(name="w", shape= [1, m], initializer=tf.random_normal_initializer(0, 1))

rula = tf.reduce_prod(tf.reshape(tf.exp( -0.5* ((tf.tile(X_train_t, (1, m))- mu)**2) / (sigma**2)),
               (-1, m, n)), axis=2)
Y_train_t = tf.reduce_sum(rula*w,axis=1) / tf.clip_by_value(tf.reduce_sum(rula,axis=1), 1e-8, 1e8)



loss = tf.losses.sigmoid_cross_entropy(y_train_t, Y_train_t)


optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(loss)





X_test_t = tf.placeholder(tf.float32, shape=[None, n])
y_test_t = tf.placeholder(tf.float32, shape=None)
rula_test = tf.reduce_prod(tf.reshape(tf.exp( -0.5* ((tf.tile(X_test_t, (1, m))- mu)**2) / (sigma**2)),
               (-1, m, n)), axis=2)
Y_test_t = tf.reduce_sum(rula_test*w,axis=1) / tf.clip_by_value(tf.reduce_sum(rula_test,axis=1), 1e-8, 1e8)
loss_test = tf.losses.sigmoid_cross_entropy(y_test_t, Y_test_t)


x_axis = []
tr_loss, te_loss = [],[]
tr_acc, te_acc = [], []
tr_f1, te_f1 = [], []
tr_prec, te_prec = [], []
tr_rec, te_rec = [], []
init=tf.global_variables_initializer()
with tf.Session() as sess:
	sess.run(init)

	for e in range(epochs):
		Y_train, loss_tr, _ = sess.run([Y_train_t, loss, optimizer], feed_dict={X_train_t: X_train, y_train_t: y_train})
		Y_test, loss_te    = sess.run([Y_test_t, loss_test], feed_dict={X_test_t: X_test, y_test_t: y_test})

		if (e+1) % 10 == 0:
			x_axis.append(e+1)

			tr_loss.append(loss_tr)
			te_loss.append(loss_te)

			Y_train = np.where(Y_train > 0, 1, 0)
			Y_test = np.where(Y_test > 0, 1, 0)

			acc_tr = accuracy_score(y_train,Y_train)
			acc_te = accuracy_score(y_test,Y_test)

			f1_tr = f1_score(y_train,Y_train)
			f1_te = f1_score(y_test,Y_test)

			prec_tr = precision_score(y_train,Y_train)
			prec_te = precision_score(y_test,Y_test)

			rec_tr = recall_score(y_train,Y_train)
			rec_te = recall_score(y_test,Y_test)

			tr_acc.append(acc_tr)
			te_acc.append(acc_te)
			tr_f1.append(f1_tr)
			te_f1.append(f1_te)
			tr_prec.append(prec_tr)
			te_prec.append(prec_te)
			tr_rec.append(rec_tr)
			te_rec.append(rec_te)

		if (e+1) % 200 == 0:
			print("Epoch ",e+1,">>>>>>>>>>>>>")

			print("loss      >>>","test:", loss_te,"\t\t train:",loss_tr)
			print("accuracy  >>>","test:", acc_te,"\t train:",acc_tr)
			print("f1-score  >>>","test:", f1_te,"\t train:",f1_tr)
			print("precision >>>","test:", prec_te,"\t train:",prec_tr)
			print("recall    >>>","test:", rec_te,"\t train:",rec_tr)
			print()

			cm_test = confusion_matrix(y_test, Y_test)
			cm_train = confusion_matrix(y_train, Y_train)

			plt.figure(int(str(e+1)+'1'))
			disp = ConfusionMatrixDisplay(confusion_matrix=cm_test,display_labels=["Not Diabetic","Diabetic"])
			disp = disp.plot()

			plt.savefig(dir_+"/cf_test-epoch"+str(e+1)+".png",transparent=True)

			plt.figure(int(str(e+1)+'2'))
			disp = ConfusionMatrixDisplay(confusion_matrix=cm_train,display_labels=["Not Diabetic","Diabetic"])
			disp = disp.plot()

			plt.savefig(dir_+"/cf_train-epoch"+str(e+1)+".png",transparent=True)



	plt.figure(1)
	plt.plot(x_axis,tr_acc,label="Train")
	plt.plot(x_axis,te_acc,label="Test")
	plt.xlabel('Epochs')
	plt.ylabel('Accuracy')
	plt.title('Accuracy over Epochs')
	plt.legend()

	plt.savefig(dir_+"/acc.png",transparent=True)

	plt.figure(2)
	plt.plot(x_axis,tr_f1,label="Train")
	plt.plot(x_axis,te_f1,label="Test")
	plt.xlabel('Epochs')
	plt.ylabel('F1-score')
	plt.title('F1-score over Epochs')
	plt.legend()

	plt.savefig(dir_+"/f1.png",transparent=True)

	plt.figure(3)
	plt.plot(x_axis,tr_prec,label="Train")
	plt.plot(x_axis,te_prec,label="Test")
	plt.xlabel('Epochs')
	plt.ylabel('Precision')
	plt.title('Precision over Epochs')
	plt.legend()

	plt.savefig(dir_+"/precision.png",transparent=True)

	plt.figure(4)
	plt.plot(x_axis,tr_rec,label="Train")
	plt.plot(x_axis,te_rec,label="Test")
	plt.xlabel('Epochs')
	plt.ylabel('Recall')
	plt.title('Recall over Epochs')
	plt.legend()

	plt.savefig(dir_+"/recall.png",transparent=True)

	plt.figure(5)
	plt.plot(x_axis,tr_loss,label="Train")
	plt.plot(x_axis,te_loss,label="Test")
	plt.xlabel('Epochs')
	plt.ylabel('Loss')
	plt.title('Loss over Epochs')
	plt.legend()

	plt.savefig(dir_+"/loss.png",transparent=True)

	mu_fin = sess.run(mu)
	mu_fin = np.reshape(mu_fin, (m, n))
	sigma_fin = sess.run(sigma)
	sigma_fin = np.reshape(sigma_fin, (m,n))
	w_fin = sess.run(w)
	x_axis_mf = np.linspace(-4, 4, 1000)
	for r in range(m):
		plt.figure(r+6)
		plt.title("Rule %d, MF for each feature [ %f ]" % ((r + 1), w_fin[0, r]))
		for i in range(n):
			plt.plot(x_axis_mf, np.exp(-0.5 * ((x_axis_mf - mu_fin[r, i]) ** 2) / (sigma_fin[r, i] ** 2)))

		plt.savefig(dir_+"/rule-"+str(r+1)+".png",transparent=True)